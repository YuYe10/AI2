{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"G:/AI/AI2/2-dataset/data/data.py\",name=\"default\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 22500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('G:/Model/bert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at G:/Model/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('G:/Model/bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=32,  # *** 梯度累加 ***\n",
    "    gradient_checkpointing=True,     # *** 梯度检查点 ***\n",
    "    optim=\"adafactor\",               # *** adafactor优化器 *** \n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "CLASS_NAME = {0: \"negative\", 1: \"positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7553ca80754d379a5e57a3d78ee303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6237, 'learning_rate': 1.770114942528736e-05, 'epoch': 0.11}\n",
      "{'loss': 0.4835, 'learning_rate': 1.540229885057471e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3975, 'learning_rate': 1.310344827586207e-05, 'epoch': 0.34}\n",
      "{'loss': 0.336, 'learning_rate': 1.0804597701149427e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2949, 'learning_rate': 8.505747126436782e-06, 'epoch': 0.57}\n",
      "{'loss': 0.2697, 'learning_rate': 6.206896551724138e-06, 'epoch': 0.68}\n",
      "{'loss': 0.263, 'learning_rate': 3.908045977011495e-06, 'epoch': 0.8}\n",
      "{'loss': 0.2705, 'learning_rate': 1.6091954022988506e-06, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee8bd6bc98b4f2798ee869fd76abfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24436816573143005, 'eval_runtime': 52.9884, 'eval_samples_per_second': 47.18, 'eval_steps_per_second': 5.907, 'epoch': 0.99}\n",
      "{'train_runtime': 1937.0624, 'train_samples_per_second': 11.616, 'train_steps_per_second': 0.045, 'train_loss': 0.35667962726505326, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87, training_loss=0.35667962726505326, metrics={'train_runtime': 1937.0624, 'train_samples_per_second': 11.616, 'train_steps_per_second': 0.045, 'train_loss': 0.35667962726505326, 'epoch': 0.99})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_model\\\\tokenizer_config.json',\n",
       " './sentiment_model\\\\special_tokens_map.json',\n",
       " './sentiment_model\\\\vocab.txt',\n",
       " './sentiment_model\\\\added_tokens.json',\n",
       " './sentiment_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./sentiment_model')\n",
    "tokenizer.save_pretrained('./sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：I absolutely loved this movie! The storyline was captivating and the acting was top-notch. A must-watch for everyone.\n",
      "模型预测结果:positive！\n",
      "输入：This movie was a complete waste of time. The plot was predictable and the characters were poorly developed.\n",
      "模型预测结果:nagetive！\n",
      "输入：An excellent film with a heartwarming story. The performances were outstanding, especially the lead actor.\n",
      "模型预测结果:positive！\n",
      "输入：I found the movie to be quite boring. It dragged on and didn't really go anywhere. Not recommended.\n",
      "模型预测结果:nagetive！\n",
      "输入：A masterpiece! The director did an amazing job bringing this story to life. The visuals were stunning.\n",
      "模型预测结果:positive！\n",
      "输入：Terrible movie. The script was awful and the acting was even worse. I can't believe I sat through the whole thing.\n",
      "模型预测结果:nagetive！\n",
      "输入：A delightful film with a perfect mix of humor and drama. The cast was great and the dialogue was witty.\n",
      "模型预测结果:positive！\n",
      "输入：I was very disappointed with this movie. It had so much potential, but it just fell flat. The ending was particularly bad.\n",
      "模型预测结果:nagetive！\n",
      "输入：One of the best movies I've seen this year. The story was original and the performances were incredibly moving.\n",
      "模型预测结果:positive！\n",
      "输入：I didn't enjoy this movie at all. It was confusing and the pacing was off. Definitely not worth watching.\n",
      "模型预测结果:nagetive！\n"
     ]
    }
   ],
   "source": [
    "test_reviews = [\n",
    "    \"I absolutely loved this movie! The storyline was captivating and the acting was top-notch. A must-watch for everyone.\",\n",
    "    \"This movie was a complete waste of time. The plot was predictable and the characters were poorly developed.\",\n",
    "    \"An excellent film with a heartwarming story. The performances were outstanding, especially the lead actor.\",\n",
    "    \"I found the movie to be quite boring. It dragged on and didn't really go anywhere. Not recommended.\",\n",
    "    \"A masterpiece! The director did an amazing job bringing this story to life. The visuals were stunning.\",\n",
    "    \"Terrible movie. The script was awful and the acting was even worse. I can't believe I sat through the whole thing.\",\n",
    "    \"A delightful film with a perfect mix of humor and drama. The cast was great and the dialogue was witty.\",\n",
    "    \"I was very disappointed with this movie. It had so much potential, but it just fell flat. The ending was particularly bad.\",\n",
    "    \"One of the best movies I've seen this year. The story was original and the performances were incredibly moving.\",\n",
    "    \"I didn't enjoy this movie at all. It was confusing and the pacing was off. Definitely not worth watching.\"\n",
    "]\n",
    "\n",
    "\n",
    "id2_label = {0: \"nagetive！\", 1: \"positive！\"}\n",
    "model.eval()\n",
    "for sen in test_reviews:\n",
    "    with torch.inference_mode():\n",
    "        inputs = tokenizer(sen, return_tensors=\"pt\")\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "        logits = model(**inputs).logits\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "        print(f\"输入：{sen}\\n模型预测结果:{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model.config.id2label = id2_label\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive！', 'score': 0.942859411239624}]\n",
      "[{'label': 'nagetive！', 'score': 0.9542161822319031}]\n",
      "[{'label': 'positive！', 'score': 0.9366816282272339}]\n",
      "[{'label': 'nagetive！', 'score': 0.9638954997062683}]\n",
      "[{'label': 'positive！', 'score': 0.9409827589988708}]\n",
      "[{'label': 'nagetive！', 'score': 0.9593591690063477}]\n",
      "[{'label': 'positive！', 'score': 0.9369943737983704}]\n",
      "[{'label': 'nagetive！', 'score': 0.9648497104644775}]\n",
      "[{'label': 'positive！', 'score': 0.9420958757400513}]\n",
      "[{'label': 'nagetive！', 'score': 0.9416175484657288}]\n"
     ]
    }
   ],
   "source": [
    "for sen in test_reviews:\n",
    "    print(pipe(sen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
